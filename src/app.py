"""Streamlit Web UI for Knowledge Atomizer."""

import os
import sys
import tempfile
from typing import List, Optional

import streamlit as st

# Add parent directory to path for imports
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.models import KnowledgeAtom
from src.parser import DocumentParser, ParserError
from src.markdown_parser import MarkdownParser
from src.transformer import KnowledgeTransformer
from src.statistics import compute_statistics
from src.exporters.csv_exporter import CSVExporter
from src.exporters.obsidian_exporter import ObsidianExporter
from src.exporters.lark_exporter import LarkExporter


class KnowledgeAtomizerApp:
    """Streamlit Web åº”ç”¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–åº”ç”¨"""
        self.docx_parser = DocumentParser()
        self.md_parser = MarkdownParser()
        self.transformer = KnowledgeTransformer()
    
    def run(self):
        """è¿è¡Œåº”ç”¨"""
        st.set_page_config(
            page_title="Knowledge Atomizer - çŸ¥è¯†åŸå­åŒ–ä¸­å°",
            page_icon="ğŸ§¬",
            layout="wide",
            initial_sidebar_state="expanded"
        )
        
        # Custom CSS for better styling
        st.markdown("""
        <style>
        .main-header {
            font-size: 2.5rem;
            font-weight: 700;
            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            margin-bottom: 0.5rem;
        }
        .sub-header {
            color: #666;
            font-size: 1.1rem;
            margin-bottom: 2rem;
        }
        .stat-card {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 1rem;
            border-radius: 10px;
            color: white;
            text-align: center;
        }
        .tree-node {
            padding: 0.5rem;
            margin: 0.25rem 0;
            border-left: 3px solid #667eea;
            background: #f8f9fa;
            border-radius: 0 5px 5px 0;
        }
        .path-badge {
            background: #e9ecef;
            padding: 0.25rem 0.5rem;
            border-radius: 4px;
            font-size: 0.8rem;
            color: #495057;
        }
        </style>
        """, unsafe_allow_html=True)
        
        # Header
        st.markdown('<p class="main-header">ğŸ§¬ Knowledge Atomizer</p>', unsafe_allow_html=True)
        st.markdown('<p class="sub-header">çŸ¥è¯†åŸå­åŒ–ä¸­å° - å°† Word/Markdown æ–‡æ¡£è½¬æ¢ä¸ºç»“æ„åŒ–çŸ¥è¯†åŸå­ï¼Œæ”¯æŒé£ä¹¦å¤šç»´è¡¨æ ¼å’Œ Obsidian</p>', unsafe_allow_html=True)
        
        # Initialize session state
        if 'atoms' not in st.session_state:
            st.session_state.atoms = None
        if 'source_file' not in st.session_state:
            st.session_state.source_file = None
        if 'source_files' not in st.session_state:
            st.session_state.source_files = []
        if 'selected_atom' not in st.session_state:
            st.session_state.selected_atom = None
        if 'csv_data' not in st.session_state:
            st.session_state.csv_data = None
        if 'zip_data' not in st.session_state:
            st.session_state.zip_data = None
        
        # Sidebar for upload and stats
        with st.sidebar:
            self._render_sidebar()
        
        # Main content
        if st.session_state.atoms:
            self._render_main_content(st.session_state.atoms)
        else:
            self._render_welcome()
    
    def _render_sidebar(self):
        """æ¸²æŸ“ä¾§è¾¹æ """
        st.header("ğŸ“¤ ä¸Šä¼ æ–‡æ¡£")
        
        uploaded_files = st.file_uploader(
            "é€‰æ‹©æ–‡æ¡£ï¼ˆæ”¯æŒå¤šé€‰ï¼‰",
            type=['docx', 'md'],
            accept_multiple_files=True,
            help="æ”¯æŒ .docx (Word) å’Œ .md (Markdown) æ ¼å¼"
        )
        
        if uploaded_files:
            st.caption(f"å·²é€‰æ‹© {len(uploaded_files)} ä¸ªæ–‡ä»¶")
            for f in uploaded_files:
                file_icon = "ğŸ“„" if f.name.endswith('.docx') else "ğŸ“"
                st.text(f"{file_icon} {f.name}")
            
            if st.button("ğŸš€ å¼€å§‹è§£æ", use_container_width=True, type="primary"):
                self._process_files(uploaded_files)
        
        # Show stats if atoms exist
        if st.session_state.atoms:
            st.divider()
            st.header("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯")
            stats = compute_statistics(st.session_state.atoms)
            
            st.metric("ğŸ“š çŸ¥è¯†åŸå­æ€»æ•°", stats.total_count)
            
            st.markdown("**å„å±‚çº§åˆ†å¸ƒ**")
            for level in range(1, 6):
                count = stats.level_counts.get(level, 0)
                if count > 0:
                    progress = count / stats.total_count if stats.total_count > 0 else 0
                    st.progress(progress, text=f"H{level}: {count} ä¸ª")
            
            st.divider()
            # Show source files
            if st.session_state.source_files:
                st.markdown(f"**æ¥æºæ–‡ä»¶** ({len(st.session_state.source_files)} ä¸ª):")
                for sf in st.session_state.source_files:
                    st.text(f"  â€¢ {sf}")
            else:
                st.markdown(f"**æ¥æºæ–‡ä»¶**: {st.session_state.source_file}")
            
            if st.button("ğŸ—‘ï¸ æ¸…é™¤æ•°æ®", use_container_width=True):
                self._clear_all_data()
                st.rerun()
    
    def _process_files(self, uploaded_files):
        """å¤„ç†å¤šä¸ªä¸Šä¼ çš„æ–‡ä»¶"""
        all_atoms = []
        source_files = []
        errors = []
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for i, uploaded_file in enumerate(uploaded_files):
            status_text.text(f"æ­£åœ¨è§£æ: {uploaded_file.name}")
            progress_bar.progress((i + 1) / len(uploaded_files))
            
            try:
                atoms = self._parse_single_file(uploaded_file)
                all_atoms.extend(atoms)
                source_files.append(uploaded_file.name)
            except Exception as e:
                errors.append(f"{uploaded_file.name}: {str(e)}")
        
        progress_bar.empty()
        status_text.empty()
        
        if all_atoms:
            st.session_state.atoms = all_atoms
            st.session_state.source_files = source_files
            st.session_state.source_file = ", ".join(source_files)
            
            # Clear cached exports
            self._clear_export_cache()
            
            st.success(f"âœ… æˆåŠŸä» {len(source_files)} ä¸ªæ–‡ä»¶ä¸­æå– {len(all_atoms)} ä¸ªçŸ¥è¯†åŸå­")
            
            if errors:
                st.warning(f"âš ï¸ {len(errors)} ä¸ªæ–‡ä»¶è§£æå¤±è´¥:\n" + "\n".join(errors))
            
            st.rerun()
        else:
            st.error("âŒ æ‰€æœ‰æ–‡ä»¶è§£æå¤±è´¥:\n" + "\n".join(errors))
    
    def _parse_single_file(self, uploaded_file) -> List[KnowledgeAtom]:
        """è§£æå•ä¸ªæ–‡ä»¶"""
        filename = uploaded_file.name
        suffix = '.md' if filename.endswith('.md') else '.docx'
        
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
            tmp.write(uploaded_file.getvalue())
            tmp_path = tmp.name
        
        try:
            if filename.endswith('.md'):
                # Parse Markdown
                tree = self.md_parser.parse(tmp_path)
                tree.source_file = filename
            else:
                # Parse Word
                tree = self.docx_parser.parse(tmp_path)
                tree.source_file = filename
            
            atoms = self.transformer.transform(tree)
            return atoms
            
        finally:
            if os.path.exists(tmp_path):
                os.unlink(tmp_path)
    
    def _clear_export_cache(self):
        """æ¸…é™¤å¯¼å‡ºç¼“å­˜"""
        st.session_state.csv_data = None
        st.session_state.zip_data = None
    
    def _clear_all_data(self):
        """æ¸…é™¤æ‰€æœ‰æ•°æ®å’Œç¼“å­˜"""
        st.session_state.atoms = None
        st.session_state.source_file = None
        st.session_state.source_files = []
        st.session_state.selected_atom = None
        self._clear_export_cache()
    
    def _render_welcome(self):
        """æ¸²æŸ“æ¬¢è¿é¡µé¢"""
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            st.markdown("""
            ### ğŸ‘‹ æ¬¢è¿ä½¿ç”¨ Knowledge Atomizer
            
            **åŠŸèƒ½ç‰¹ç‚¹ï¼š**
            - ğŸ“„ è§£æ Word (.docx) å’Œ Markdown (.md) æ–‡æ¡£
            - ğŸ“š æ”¯æŒæ‰¹é‡ä¸Šä¼ å¤šä¸ªæ–‡ä»¶
            - ğŸ§¬ å°†å†…å®¹æ‹†è§£ä¸ºç‹¬ç«‹çš„çŸ¥è¯†åŸå­
            - ğŸŒ³ å¯è§†åŒ–çŸ¥è¯†æ ‘ç»“æ„
            - ğŸ“¤ å¯¼å‡ºåˆ°é£ä¹¦å¤šç»´è¡¨æ ¼ã€Obsidianã€CSV
            
            **ä½¿ç”¨æ–¹æ³•ï¼š**
            1. åœ¨å·¦ä¾§ä¸Šä¼ æ–‡æ¡£ï¼ˆæ”¯æŒå¤šé€‰ï¼‰
            2. ç‚¹å‡»"å¼€å§‹è§£æ"æŒ‰é’®
            3. é¢„è§ˆçŸ¥è¯†ç»“æ„
            4. é€‰æ‹©å¯¼å‡ºæ ¼å¼
            
            **æ”¯æŒçš„æ ¼å¼ï¼š**
            - `.docx` - Microsoft Word æ–‡æ¡£
            - `.md` - Markdown æ–‡æ¡£ï¼ˆATX é£æ ¼æ ‡é¢˜ï¼‰
            
            ---
            *è¯·åœ¨å·¦ä¾§ä¸Šä¼ æ–‡æ¡£å¼€å§‹ä½¿ç”¨*
    
    
    def _render_main_content(self, atoms: List[KnowledgeAtom]):
        """æ¸²æŸ“ä¸»å†…å®¹åŒº"""
        tab1, tab2, tab3, tab4 = st.tabs(["ğŸŒ³ çŸ¥è¯†æ ‘", "ğŸ“‹ åˆ—è¡¨è§†å›¾", "ğŸ“Š å¯è§†åŒ–", "ğŸ“¥ å¯¼å‡º"])
        
        with tab1:
            self._render_tree_view(atoms)
        
        with tab2:
            self._render_list_view(atoms)
        
        with tab3:
            self._render_visualization(atoms)
        
        with tab4:
            self._render_export_section(atoms)
    
    def _render_tree_view(self, atoms: List[KnowledgeAtom]):
        """æ¸²æŸ“æ ‘å½¢è§†å›¾"""
        st.subheader("ğŸŒ³ çŸ¥è¯†æ ‘ç»“æ„")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.markdown("**å±‚çº§ç»“æ„**")
            root_atoms = [a for a in atoms if a.parent_id is None]
            
            def render_tree_node(atom: KnowledgeAtom, depth: int = 0):
                indent = "ã€€ã€€" * depth
                prefix = "â”œâ”€ " if depth > 0 else ""
                level_colors = {1: "ğŸ”´", 2: "ğŸŸ ", 3: "ğŸŸ¡", 4: "ğŸŸ¢", 5: "ğŸ”µ"}
                level_icon = level_colors.get(atom.level, "âšª")
                
                if st.button(
                    f"{indent}{prefix}{level_icon} {atom.title}",
                    key=f"tree_{atom.id}",
                    use_container_width=True
                ):
                    st.session_state.selected_atom = atom
                
                children = [a for a in atoms if a.parent_id == atom.id]
                for child in children:
                    render_tree_node(child, depth + 1)
            
            for root in root_atoms:
                render_tree_node(root)
        
        with col2:
            st.markdown("**è¯¦ç»†ä¿¡æ¯**")
            if st.session_state.selected_atom:
                atom = st.session_state.selected_atom
                
                st.markdown(f"### {atom.title}")
                st.markdown(f"**å®Œæ•´è·¯å¾„**: `{atom.path}`")
                
                info_col1, info_col2 = st.columns(2)
                with info_col1:
                    st.markdown(f"**å±‚çº§**: H{atom.level}")
                    st.markdown(f"**çˆ¶èŠ‚ç‚¹**: {atom.parent_title or '(æ ¹èŠ‚ç‚¹)'}")
                with info_col2:
                    st.markdown(f"**ID**: `{atom.id[:8]}...`")
                    children_count = len([a for a in atoms if a.parent_id == atom.id])
                    st.markdown(f"**å­èŠ‚ç‚¹æ•°**: {children_count}")
                
                st.divider()
                st.markdown("**å†…å®¹**")
                if atom.content:
                    st.markdown(atom.content)
                else:
                    st.caption("(æ— å†…å®¹)")
            else:
                st.info("ğŸ‘ˆ ç‚¹å‡»å·¦ä¾§èŠ‚ç‚¹æŸ¥çœ‹è¯¦æƒ…")
    
    def _render_list_view(self, atoms: List[KnowledgeAtom]):
        """æ¸²æŸ“åˆ—è¡¨è§†å›¾"""
        st.subheader("ğŸ“‹ çŸ¥è¯†åŸå­åˆ—è¡¨")
        
        # Filters
        col1, col2, col3 = st.columns(3)
        with col1:
            level_filter = st.multiselect(
                "ç­›é€‰å±‚çº§",
                options=[1, 2, 3, 4, 5],
                default=[1, 2, 3, 4, 5],
                format_func=lambda x: f"H{x}"
            )
        with col2:
            search_term = st.text_input("ğŸ” æœç´¢æ ‡é¢˜æˆ–å†…å®¹")
        with col3:
            sort_by = st.selectbox("æ’åº", ["å±‚çº§", "æ ‡é¢˜", "è·¯å¾„é•¿åº¦"])
        
        # Filter atoms
        filtered = [a for a in atoms if a.level in level_filter]
        if search_term:
            filtered = [a for a in filtered if search_term.lower() in a.title.lower() or search_term.lower() in (a.content or "").lower()]
        
        # Sort
        if sort_by == "å±‚çº§":
            filtered.sort(key=lambda x: x.level)
        elif sort_by == "æ ‡é¢˜":
            filtered.sort(key=lambda x: x.title)
        else:
            filtered.sort(key=lambda x: len(x.path))
        
        st.caption(f"æ˜¾ç¤º {len(filtered)} / {len(atoms)} ä¸ªçŸ¥è¯†åŸå­")
        
        # Display as table
        for atom in filtered:
            with st.expander(f"H{atom.level} | {atom.title}", expanded=False):
                st.markdown(f"**è·¯å¾„**: `{atom.path}`")
                if atom.content:
                    st.markdown(atom.content[:500] + ("..." if len(atom.content) > 500 else ""))
                else:
                    st.caption("(æ— å†…å®¹)")
    
    def _render_visualization(self, atoms: List[KnowledgeAtom]):
        """æ¸²æŸ“å¯è§†åŒ–å›¾è¡¨"""
        import pandas as pd
        
        st.subheader("ğŸ“Š çŸ¥è¯†ç»“æ„å¯è§†åŒ–")
        
        stats = compute_statistics(atoms)
        
        # Row 1: Key metrics
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ğŸ“š æ€»åŸå­æ•°", stats.total_count)
        with col2:
            avg_content_len = sum(len(a.content or "") for a in atoms) / len(atoms) if atoms else 0
            st.metric("ğŸ“ å¹³å‡å†…å®¹é•¿åº¦", f"{avg_content_len:.0f} å­—")
        with col3:
            max_depth = max((a.path.count(">") + 1 for a in atoms), default=0)
            st.metric("ğŸŒ² æœ€å¤§æ·±åº¦", f"{max_depth} å±‚")
        with col4:
            root_count = len([a for a in atoms if a.parent_id is None])
            st.metric("ğŸŒ± æ ¹èŠ‚ç‚¹æ•°", root_count)
        
        st.divider()
        
        # Row 2: Charts
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**ğŸ“Š å±‚çº§åˆ†å¸ƒ**")
            level_data = pd.DataFrame({
                'å±‚çº§': [f'H{i}' for i in range(1, 6)],
                'æ•°é‡': [stats.level_counts.get(i, 0) for i in range(1, 6)]
            })
            st.bar_chart(level_data.set_index('å±‚çº§'))
        
        with col2:
            st.markdown("**ğŸ“ å†…å®¹é•¿åº¦åˆ†å¸ƒ**")
            # Group content lengths into buckets
            lengths = [len(a.content or "") for a in atoms]
            buckets = {'0': 0, '1-100': 0, '101-500': 0, '501-1000': 0, '1000+': 0}
            for l in lengths:
                if l == 0:
                    buckets['0'] += 1
                elif l <= 100:
                    buckets['1-100'] += 1
                elif l <= 500:
                    buckets['101-500'] += 1
                elif l <= 1000:
                    buckets['501-1000'] += 1
                else:
                    buckets['1000+'] += 1
            length_data = pd.DataFrame({
                'é•¿åº¦åŒºé—´': list(buckets.keys()),
                'æ•°é‡': list(buckets.values())
            })
            st.bar_chart(length_data.set_index('é•¿åº¦åŒºé—´'))
        
        st.divider()
        
        # Row 3: Tree visualization using graphviz
        st.markdown("**ğŸŒ³ çŸ¥è¯†æ ‘ç»“æ„å›¾**")
        
        try:
            # Generate graphviz DOT format
            dot_code = self._generate_graphviz(atoms)
            st.graphviz_chart(dot_code)
        except Exception as e:
            st.warning(f"å›¾è¡¨æ¸²æŸ“å¤±è´¥: {e}")
            st.code(self._generate_mermaid(atoms), language="mermaid")
        
        st.divider()
        
        # Row 4: Data table
        st.markdown("**ğŸ“‹ æ•°æ®æ¦‚è§ˆ**")
        df = pd.DataFrame([{
            'æ ‡é¢˜': a.title[:30] + ('...' if len(a.title) > 30 else ''),
            'å±‚çº§': f'H{a.level}',
            'å†…å®¹é•¿åº¦': len(a.content or ""),
            'å­èŠ‚ç‚¹æ•°': len([x for x in atoms if x.parent_id == a.id]),
            'è·¯å¾„æ·±åº¦': a.path.count(">") + 1
        } for a in atoms[:50]])
        st.dataframe(df, use_container_width=True)
        
        if len(atoms) > 50:
            st.caption(f"ä»…æ˜¾ç¤ºå‰ 50 æ¡ï¼Œå…± {len(atoms)} æ¡")
    
    def _generate_graphviz(self, atoms: List[KnowledgeAtom]) -> str:
        """ç”Ÿæˆ Graphviz DOT æ ¼å¼å›¾è¡¨"""
        lines = [
            'digraph G {',
            '    rankdir=TB;',
            '    node [shape=box, style="rounded,filled", fontname="Arial"];',
            '    edge [color="#666666"];'
        ]
        
        # Color mapping for levels
        colors = {1: '#ff6b6b', 2: '#ffa94d', 3: '#ffd43b', 4: '#69db7c', 5: '#74c0fc'}
        
        # Limit nodes for readability
        display_atoms = atoms[:40]
        
        for atom in display_atoms:
            safe_title = atom.title[:15].replace('"', "'").replace('\n', ' ')
            if len(atom.title) > 15:
                safe_title += '...'
            node_id = 'n' + atom.id[:8].replace('-', '')
            color = colors.get(atom.level, '#e9ecef')
            lines.append(f'    {node_id} [label="{safe_title}", fillcolor="{color}"];')
            
            if atom.parent_id:
                parent_id = 'n' + atom.parent_id[:8].replace('-', '')
                lines.append(f'    {parent_id} -> {node_id};')
        
        if len(atoms) > 40:
            lines.append(f'    more [label="... è¿˜æœ‰ {len(atoms) - 40} ä¸ªèŠ‚ç‚¹", style="dashed"];')
        
        lines.append('}')
        return '\n'.join(lines)
    
    def _generate_mermaid(self, atoms: List[KnowledgeAtom]) -> str:
        """ç”Ÿæˆ Mermaid å›¾è¡¨ä»£ç """
        lines = ["graph TD"]
        
        # Limit to first 30 nodes for readability
        display_atoms = atoms[:30]
        
        for atom in display_atoms:
            safe_title = atom.title[:20].replace('"', "'").replace("[", "(").replace("]", ")")
            node_id = atom.id[:8]
            lines.append(f'    {node_id}["{safe_title}"]')
            
            if atom.parent_id:
                parent_id = atom.parent_id[:8]
                lines.append(f'    {parent_id} --> {node_id}')
        
        if len(atoms) > 30:
            lines.append(f'    more["... è¿˜æœ‰ {len(atoms) - 30} ä¸ªèŠ‚ç‚¹"]')
        
        return "\n".join(lines)
    
    def _render_export_section(self, atoms: List[KnowledgeAtom]):
        """æ¸²æŸ“å¯¼å‡ºé€‰é¡¹"""
        st.subheader("ğŸ“¥ å¯¼å‡ºçŸ¥è¯†åŸå­")
        st.caption(f"æ¥æºæ–‡ä»¶: {st.session_state.source_file} | å…± {len(atoms)} ä¸ªçŸ¥è¯†åŸå­")
        
        # Initialize session state for exports
        if 'csv_data' not in st.session_state:
            st.session_state.csv_data = None
        if 'zip_data' not in st.session_state:
            st.session_state.zip_data = None
        
        # Pre-generate exports
        self._prepare_exports(atoms)
        
        # Three columns for export buttons
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("### ğŸ“„ CSV")
            st.caption("Excel å…¼å®¹æ ¼å¼")
            if st.session_state.csv_data:
                st.download_button(
                    label="â¬‡ï¸ ä¸‹è½½ CSV",
                    data=st.session_state.csv_data,
                    file_name=f"{st.session_state.source_file or 'export'}_atoms.csv",
                    mime="text/csv",
                    use_container_width=True
                )
        
        with col2:
            st.markdown("### ğŸ“š Obsidian")
            st.caption("çŸ¥è¯†åº“ ZIP åŒ…")
            if st.session_state.zip_data:
                st.download_button(
                    label="â¬‡ï¸ ä¸‹è½½ ZIP",
                    data=st.session_state.zip_data,
                    file_name=f"{st.session_state.source_file or 'export'}_obsidian.zip",
                    mime="application/zip",
                    use_container_width=True
                )
        
        with col3:
            st.markdown("### ğŸ¦ é£ä¹¦")
            st.caption("åŒæ­¥åˆ°å¤šç»´è¡¨æ ¼")
            # Show sync button only if config exists
            if st.session_state.get('lark_configured'):
                if st.button("ğŸš€ åŒæ­¥åˆ°é£ä¹¦", key="lark_sync_btn", use_container_width=True, type="primary"):
                    self._export_lark(
                        atoms,
                        st.session_state.lark_app_id,
                        st.session_state.lark_app_secret,
                        st.session_state.lark_app_token,
                        st.session_state.lark_table_id
                    )
            else:
                st.info("è¯·å…ˆé…ç½®é£ä¹¦ API â†“")
        
        st.divider()
        
        # Lark config in expander
        with st.expander("âš™ï¸ é£ä¹¦ API é…ç½®", expanded=not st.session_state.get('lark_configured')):
            col1, col2 = st.columns(2)
            with col1:
                app_id = st.text_input("App ID", placeholder="cli_xxxxxxxxxx", key="lark_app_id_input")
                app_token = st.text_input("App Token", placeholder="bascnxxxxxxxxxx", key="lark_app_token_input")
            with col2:
                app_secret = st.text_input("App Secret", type="password", placeholder="xxxxxxxxxx", key="lark_app_secret_input")
                table_id = st.text_input("Table ID", placeholder="tblxxxxxxxxxx", key="lark_table_id_input")
            
            st.caption("ğŸ’¡ é£ä¹¦å¤šç»´è¡¨æ ¼éœ€è¦çš„å­—æ®µï¼šåŸå­IDã€æ ‡é¢˜ã€å†…å®¹ã€å±‚çº§ã€çˆ¶èŠ‚ç‚¹ã€æ¥æºæ–‡ä»¶ã€çŸ¥è¯†è·¯å¾„")
            
            if st.button("ğŸ’¾ ä¿å­˜é…ç½®", use_container_width=True):
                if all([app_id, app_secret, app_token, table_id]):
                    st.session_state.lark_app_id = app_id
                    st.session_state.lark_app_secret = app_secret
                    st.session_state.lark_app_token = app_token
                    st.session_state.lark_table_id = table_id
                    st.session_state.lark_configured = True
                    st.success("âœ… é…ç½®å·²ä¿å­˜")
                    st.rerun()
                else:
                    st.error("è¯·å¡«å†™æ‰€æœ‰é…ç½®é¡¹")
    
    def _prepare_exports(self, atoms: List[KnowledgeAtom]):
        """é¢„ç”Ÿæˆå¯¼å‡ºæ–‡ä»¶"""
        # Generate CSV if not exists
        if st.session_state.csv_data is None:
            try:
                exporter = CSVExporter()
                result = exporter.export(atoms)
                if result.success and result.file_path:
                    with open(result.file_path, 'rb') as f:
                        st.session_state.csv_data = f.read()
                    os.unlink(result.file_path)
            except Exception:
                pass
        
        # Generate ZIP if not exists
        if st.session_state.zip_data is None:
            try:
                exporter = ObsidianExporter()
                result = exporter.export(atoms)
                if result.success and result.file_path:
                    with open(result.file_path, 'rb') as f:
                        st.session_state.zip_data = f.read()
                    os.unlink(result.file_path)
            except Exception:
                pass
    
    def _export_lark(self, atoms: List[KnowledgeAtom], app_id: str, app_secret: str, app_token: str, table_id: str):
        """å¯¼å‡ºåˆ°é£ä¹¦"""
        try:
            with st.spinner("æ­£åœ¨åŒæ­¥åˆ°é£ä¹¦..."):
                exporter = LarkExporter(app_id, app_secret, app_token, table_id)
                result = exporter.export(atoms)
                
                if result.success:
                    st.success(result.message)
                else:
                    st.error(result.message)
        except Exception as e:
            st.error(f"åŒæ­¥å¤±è´¥: {str(e)}")


def main():
    """Main entry point."""
    app = KnowledgeAtomizerApp()
    app.run()


if __name__ == "__main__":
    main()
