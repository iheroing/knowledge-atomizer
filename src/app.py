"""Streamlit Web UI for Knowledge Atomizer."""

import os
import sys
import tempfile
from typing import List, Optional

import streamlit as st

# Add parent directory to path for imports
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.models import KnowledgeAtom
from src.parser import DocumentParser, ParserError
from src.markdown_parser import MarkdownParser
from src.transformer import KnowledgeTransformer
from src.statistics import compute_statistics
from src.exporters.csv_exporter import CSVExporter
from src.exporters.obsidian_exporter import ObsidianExporter
from src.exporters.lark_exporter import LarkExporter


class KnowledgeAtomizerApp:
    """Streamlit Web åº”ç”¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–åº”ç”¨"""
        self.docx_parser = DocumentParser()
        self.md_parser = MarkdownParser()
        self.transformer = KnowledgeTransformer()
    
    def run(self):
        """è¿è¡Œåº”ç”¨"""
        st.set_page_config(
            page_title="Knowledge Atomizer - çŸ¥è¯†åŸå­åŒ–ä¸­å°",
            page_icon="ğŸ§¬",
            layout="wide",
            initial_sidebar_state="expanded"
        )
        
        # Custom CSS for better styling
        st.markdown("""
        <style>
        .main-header {
            font-size: 2.5rem;
            font-weight: 700;
            background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            margin-bottom: 0.5rem;
        }
        .sub-header {
            color: #666;
            font-size: 1.1rem;
            margin-bottom: 2rem;
        }
        .stat-card {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 1rem;
            border-radius: 10px;
            color: white;
            text-align: center;
        }
        .tree-node {
            padding: 0.5rem;
            margin: 0.25rem 0;
            border-left: 3px solid #667eea;
            background: #f8f9fa;
            border-radius: 0 5px 5px 0;
        }
        .path-badge {
            background: #e9ecef;
            padding: 0.25rem 0.5rem;
            border-radius: 4px;
            font-size: 0.8rem;
            color: #495057;
        }
        </style>
        """, unsafe_allow_html=True)
        
        # Header
        st.markdown('<p class="main-header">ğŸ§¬ Knowledge Atomizer</p>', unsafe_allow_html=True)
        st.markdown('<p class="sub-header">çŸ¥è¯†åŸå­åŒ–ä¸­å° - å°† Word/Markdown æ–‡æ¡£è½¬æ¢ä¸ºç»“æ„åŒ–çŸ¥è¯†åŸå­ï¼Œæ”¯æŒé£ä¹¦å¤šç»´è¡¨æ ¼å’Œ Obsidian</p>', unsafe_allow_html=True)
        
        # Initialize session state
        if 'atoms' not in st.session_state:
            st.session_state.atoms = None
        if 'source_file' not in st.session_state:
            st.session_state.source_file = None
        if 'source_files' not in st.session_state:
            st.session_state.source_files = []
        if 'selected_atom' not in st.session_state:
            st.session_state.selected_atom = None
        if 'csv_data' not in st.session_state:
            st.session_state.csv_data = None
        if 'zip_data' not in st.session_state:
            st.session_state.zip_data = None
        
        # Sidebar for upload and stats
        with st.sidebar:
            self._render_sidebar()
        
        # Main content
        if st.session_state.atoms:
            self._render_main_content(st.session_state.atoms)
        else:
            self._render_welcome()
    
    def _render_sidebar(self):
        """æ¸²æŸ“ä¾§è¾¹æ """
        st.header("ğŸ“¤ ä¸Šä¼ æ–‡æ¡£")
        
        uploaded_files = st.file_uploader(
            "é€‰æ‹©æ–‡æ¡£ï¼ˆæ”¯æŒå¤šé€‰ï¼‰",
            type=['docx', 'md'],
            accept_multiple_files=True,
            help="æ”¯æŒ .docx (Word) å’Œ .md (Markdown) æ ¼å¼"
        )
        
        if uploaded_files:
            st.caption(f"å·²é€‰æ‹© {len(uploaded_files)} ä¸ªæ–‡ä»¶")
            for f in uploaded_files:
                file_icon = "ğŸ“„" if f.name.endswith('.docx') else "ğŸ“"
                st.text(f"{file_icon} {f.name}")
            
            if st.button("ğŸš€ å¼€å§‹è§£æ", use_container_width=True, type="primary"):
                self._process_files(uploaded_files)
        
        # Show stats if atoms exist
        if st.session_state.atoms:
            st.divider()
            st.header("ğŸ“Š ç»Ÿè®¡ä¿¡æ¯")
            stats = compute_statistics(st.session_state.atoms)
            
            st.metric("ğŸ“š çŸ¥è¯†åŸå­æ€»æ•°", stats.total_count)
            
            st.markdown("**å„å±‚çº§åˆ†å¸ƒ**")
            for level in range(1, 6):
                count = stats.level_counts.get(level, 0)
                if count > 0:
                    progress = count / stats.total_count if stats.total_count > 0 else 0
                    st.progress(progress, text=f"H{level}: {count} ä¸ª")
            
            st.divider()
            # Show source files
            if st.session_state.source_files:
                st.markdown(f"**æ¥æºæ–‡ä»¶** ({len(st.session_state.source_files)} ä¸ª):")
                for sf in st.session_state.source_files:
                    st.text(f"  â€¢ {sf}")
            else:
                st.markdown(f"**æ¥æºæ–‡ä»¶**: {st.session_state.source_file}")
            
            if st.button("ğŸ—‘ï¸ æ¸…é™¤æ•°æ®", use_container_width=True):
                self._clear_all_data()
                st.rerun()
    
    def _process_files(self, uploaded_files):
        """å¤„ç†å¤šä¸ªä¸Šä¼ çš„æ–‡ä»¶"""
        all_atoms = []
        source_files = []
        errors = []
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for i, uploaded_file in enumerate(uploaded_files):
            status_text.text(f"æ­£åœ¨è§£æ: {uploaded_file.name}")
            progress_bar.progress((i + 1) / len(uploaded_files))
            
            try:
                atoms = self._parse_single_file(uploaded_file)
                all_atoms.extend(atoms)
                source_files.append(uploaded_file.name)
            except Exception as e:
                errors.append(f"{uploaded_file.name}: {str(e)}")
        
        progress_bar.empty()
        status_text.empty()
        
        if all_atoms:
            st.session_state.atoms = all_atoms
            st.session_state.source_files = source_files
            st.session_state.source_file = ", ".join(source_files)
            
            # Clear cached exports
            self._clear_export_cache()
            
            st.success(f"âœ… æˆåŠŸä» {len(source_files)} ä¸ªæ–‡ä»¶ä¸­æå– {len(all_atoms)} ä¸ªçŸ¥è¯†åŸå­")
            
            if errors:
                st.warning(f"âš ï¸ {len(errors)} ä¸ªæ–‡ä»¶è§£æå¤±è´¥:\n" + "\n".join(errors))
            
            st.rerun()
        else:
            st.error("âŒ æ‰€æœ‰æ–‡ä»¶è§£æå¤±è´¥:\n" + "\n".join(errors))
    
    def _parse_single_file(self, uploaded_file) -> List[KnowledgeAtom]:
        """è§£æå•ä¸ªæ–‡ä»¶"""
        filename = uploaded_file.name
        suffix = '.md' if filename.endswith('.md') else '.docx'
        
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
            tmp.write(uploaded_file.getvalue())
            tmp_path = tmp.name
        
        try:
            if filename.endswith('.md'):
                # Parse Markdown
                tree = self.md_parser.parse(tmp_path)
                tree.source_file = filename
            else:
                # Parse Word
                tree = self.docx_parser.parse(tmp_path)
                tree.source_file = filename
            
            atoms = self.transformer.transform(tree)
            return atoms
            
        finally:
            if os.path.exists(tmp_path):
                os.unlink(tmp_path)
    
    def _clear_export_cache(self):
        """æ¸…é™¤å¯¼å‡ºç¼“å­˜"""
        st.session_state.csv_data = None
        st.session_state.zip_data = None
    
    def _clear_all_data(self):
        """æ¸…é™¤æ‰€æœ‰æ•°æ®å’Œç¼“å­˜"""
        st.session_state.atoms = None
        st.session_state.source_file = None
        st.session_state.source_files = []
        st.session_state.selected_atom = None
        self._clear_export_cache()
    
    def _render_welcome(self):
        """æ¸²æŸ“æ¬¢è¿é¡µé¢"""
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            st.markdown("""
            ### ğŸ‘‹ æ¬¢è¿ä½¿ç”¨ Knowledge Atomizer
            
            **åŠŸèƒ½ç‰¹ç‚¹ï¼š**
            - ğŸ“„ è§£æ Word (.docx) å’Œ Markdown (.md) æ–‡æ¡£
            - ğŸ“š æ”¯æŒæ‰¹é‡ä¸Šä¼ å¤šä¸ªæ–‡ä»¶
            - ğŸ§¬ å°†å†…å®¹æ‹†è§£ä¸ºç‹¬ç«‹çš„çŸ¥è¯†åŸå­
            - ğŸŒ³ å¯è§†åŒ–çŸ¥è¯†æ ‘ç»“æ„
            - ğŸ“¤ å¯¼å‡ºåˆ°é£ä¹¦å¤šç»´è¡¨æ ¼ã€Obsidianã€CSV
            
            **ä½¿ç”¨æ–¹æ³•ï¼š**
            1. åœ¨å·¦ä¾§ä¸Šä¼ æ–‡æ¡£ï¼ˆæ”¯æŒå¤šé€‰ï¼‰
            2. ç‚¹å‡»"å¼€å§‹è§£æ"æŒ‰é’®
            3. é¢„è§ˆçŸ¥è¯†ç»“æ„
            4. é€‰æ‹©å¯¼å‡ºæ ¼å¼
            
            **æ”¯æŒçš„æ ¼å¼ï¼š**
            - `.docx` - Microsoft Word æ–‡æ¡£
            - `.md` - Markdown æ–‡æ¡£ï¼ˆATX é£æ ¼æ ‡é¢˜ï¼‰
            
            ---
            *è¯·åœ¨å·¦ä¾§ä¸Šä¼ æ–‡æ¡£å¼€å§‹ä½¿ç”¨*
            """)
    
    def _render_main_content(self, atoms: List[KnowledgeAtom]):
        """æ¸²æŸ“ä¸»å†…å®¹åŒº"""
        tab1, tab2, tab3, tab4 = st.tabs(["ğŸŒ³ çŸ¥è¯†æ ‘", "ğŸ“‹ åˆ—è¡¨è§†å›¾", "ğŸ“Š å¯è§†åŒ–", "ğŸ“¥ å¯¼å‡º"])
        
        with tab1:
            self._render_tree_view(atoms)
        
        with tab2:
            self._render_list_view(atoms)
        
        with tab3:
            self._render_visualization(atoms)
        
        with tab4:
            self._render_export_section(atoms)
    
    def _render_tree_view(self, atoms: List[KnowledgeAtom]):
        """æ¸²æŸ“æ ‘å½¢è§†å›¾ - ä¼˜åŒ–ç‰ˆæœ¬ï¼Œä½¿ç”¨ selectbox æ›¿ä»£å¤§é‡æŒ‰é’®"""
        st.subheader("ğŸŒ³ çŸ¥è¯†æ ‘ç»“æ„")
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.markdown("**é€‰æ‹©çŸ¥è¯†åŸå­**")
            
            # ä½¿ç”¨ selectbox æ›¿ä»£å¤§é‡æŒ‰é’®ï¼Œå¤§å¹…æå‡æ€§èƒ½
            atom_options = []
            atom_map = {}
            
            for atom in atoms:
                level_icons = {1: "ğŸ”´", 2: "ğŸŸ ", 3: "ğŸŸ¡", 4: "ğŸŸ¢", 5: "ğŸ”µ"}
                icon = level_icons.get(atom.level, "âšª")
                indent = "  " * (atom.level - 1)
                label = f"{indent}{icon} H{atom.level} | {atom.title[:40]}"
                atom_options.append(label)
                atom_map[label] = atom
            
            if atom_options:
                selected_label = st.selectbox(
                    "é€‰æ‹©èŠ‚ç‚¹æŸ¥çœ‹è¯¦æƒ…",
                    options=atom_options,
                    index=0,
                    label_visibility="collapsed"
                )
                
                if selected_label:
                    st.session_state.selected_atom = atom_map[selected_label]
            
            # æ˜¾ç¤ºç®€åŒ–çš„æ ‘å½¢ç»“æ„ï¼ˆåªæ˜¾ç¤ºå‰20ä¸ªæ ¹èŠ‚ç‚¹ï¼‰
            st.markdown("**å±‚çº§é¢„è§ˆ**")
            root_atoms = [a for a in atoms if a.parent_id is None][:20]
            
            for root in root_atoms:
                self._render_tree_text(root, atoms, 0, max_depth=2)
            
            if len([a for a in atoms if a.parent_id is None]) > 20:
                st.caption(f"... è¿˜æœ‰æ›´å¤šæ ¹èŠ‚ç‚¹")
        
        with col2:
            st.markdown("**è¯¦ç»†ä¿¡æ¯**")
            if st.session_state.selected_atom:
                atom = st.session_state.selected_atom
                
                st.markdown(f"### {atom.title}")
                st.markdown(f"**å®Œæ•´è·¯å¾„**: `{atom.path}`")
                
                info_col1, info_col2 = st.columns(2)
                with info_col1:
                    st.markdown(f"**å±‚çº§**: H{atom.level}")
                    st.markdown(f"**çˆ¶èŠ‚ç‚¹**: {atom.parent_title or '(æ ¹èŠ‚ç‚¹)'}")
                with info_col2:
                    st.markdown(f"**ID**: `{atom.id[:8]}...`")
                    children_count = len([a for a in atoms if a.parent_id == atom.id])
                    st.markdown(f"**å­èŠ‚ç‚¹æ•°**: {children_count}")
                
                st.divider()
                st.markdown("**å†…å®¹**")
                if atom.content:
                    st.markdown(atom.content)
                else:
                    st.caption("(æ— å†…å®¹)")
            else:
                st.info("ğŸ‘ˆ ä»å·¦ä¾§é€‰æ‹©èŠ‚ç‚¹æŸ¥çœ‹è¯¦æƒ…")
    
    def _render_tree_text(self, atom: KnowledgeAtom, all_atoms: List[KnowledgeAtom], depth: int, max_depth: int = 2):
        """æ¸²æŸ“æ ‘å½¢æ–‡æœ¬ï¼ˆç®€åŒ–ç‰ˆï¼Œé™åˆ¶æ·±åº¦ï¼‰"""
        if depth > max_depth:
            return
        
        indent = "ã€€" * depth
        prefix = "â”œâ”€ " if depth > 0 else ""
        level_icons = {1: "ğŸ”´", 2: "ğŸŸ ", 3: "ğŸŸ¡", 4: "ğŸŸ¢", 5: "ğŸ”µ"}
        icon = level_icons.get(atom.level, "âšª")
        
        st.text(f"{indent}{prefix}{icon} {atom.title[:30]}")
        
        children = [a for a in all_atoms if a.parent_id == atom.id][:5]
        for child in children:
            self._render_tree_text(child, all_atoms, depth + 1, max_depth)
    
    def _render_list_view(self, atoms: List[KnowledgeAtom]):
        """æ¸²æŸ“åˆ—è¡¨è§†å›¾"""
        st.subheader("ğŸ“‹ çŸ¥è¯†åŸå­åˆ—è¡¨")
        
        # Filters
        col1, col2, col3 = st.columns(3)
        with col1:
            level_filter = st.multiselect(
                "ç­›é€‰å±‚çº§",
                options=[1, 2, 3, 4, 5],
                default=[1, 2, 3, 4, 5],
                format_func=lambda x: f"H{x}"
            )
        with col2:
            search_term = st.text_input("ğŸ” æœç´¢æ ‡é¢˜æˆ–å†…å®¹")
        with col3:
            sort_by = st.selectbox("æ’åº", ["å±‚çº§", "æ ‡é¢˜", "è·¯å¾„é•¿åº¦"])
        
        # Filter atoms
        filtered = [a for a in atoms if a.level in level_filter]
        if search_term:
            filtered = [a for a in filtered if search_term.lower() in a.title.lower() or search_term.lower() in (a.content or "").lower()]
        
        # Sort
        if sort_by == "å±‚çº§":
            filtered.sort(key=lambda x: x.level)
        elif sort_by == "æ ‡é¢˜":
            filtered.sort(key=lambda x: x.title)
        else:
            filtered.sort(key=lambda x: len(x.path))
        
        st.caption(f"æ˜¾ç¤º {len(filtered)} / {len(atoms)} ä¸ªçŸ¥è¯†åŸå­")
        
        # Display as table
        for atom in filtered:
            with st.expander(f"H{atom.level} | {atom.title}", expanded=False):
                st.markdown(f"**è·¯å¾„**: `{atom.path}`")
                if atom.content:
                    st.markdown(atom.content[:500] + ("..." if len(atom.content) > 500 else ""))
                else:
                    st.caption("(æ— å†…å®¹)")
    
    def _render_visualization(self, atoms: List[KnowledgeAtom]):
        """æ¸²æŸ“å¯è§†åŒ–å›¾è¡¨ - å¢å¼ºç‰ˆï¼Œå¸¦ä¸‹è½½åŠŸèƒ½"""
        import pandas as pd
        import json
        
        st.subheader("ğŸ“Š çŸ¥è¯†ç»“æ„å¯è§†åŒ–")
        
        stats = compute_statistics(atoms)
        
        # Row 1: Key metrics with styled cards
        st.markdown("""
        <style>
        .metric-card {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 1.2rem;
            border-radius: 12px;
            color: white;
            text-align: center;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }
        .metric-value {
            font-size: 2rem;
            font-weight: bold;
        }
        .metric-label {
            font-size: 0.9rem;
            opacity: 0.9;
        }
        </style>
        """, unsafe_allow_html=True)
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ğŸ“š æ€»åŸå­æ•°", stats.total_count)
        with col2:
            avg_content_len = sum(len(a.content or "") for a in atoms) / len(atoms) if atoms else 0
            st.metric("ğŸ“ å¹³å‡å†…å®¹é•¿åº¦", f"{avg_content_len:.0f} å­—")
        with col3:
            max_depth = max((a.path.count(">") + 1 for a in atoms), default=0)
            st.metric("ğŸŒ² æœ€å¤§æ·±åº¦", f"{max_depth} å±‚")
        with col4:
            root_count = len([a for a in atoms if a.parent_id is None])
            st.metric("ğŸŒ± æ ¹èŠ‚ç‚¹æ•°", root_count)
        
        st.divider()
        
        # Row 2: Charts with download
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**ğŸ“Š å±‚çº§åˆ†å¸ƒ**")
            level_data = pd.DataFrame({
                'å±‚çº§': [f'H{i}' for i in range(1, 6)],
                'æ•°é‡': [stats.level_counts.get(i, 0) for i in range(1, 6)]
            })
            st.bar_chart(level_data.set_index('å±‚çº§'))
            # ä¸‹è½½å±‚çº§åˆ†å¸ƒæ•°æ®
            st.download_button(
                "â¬‡ï¸ ä¸‹è½½å±‚çº§æ•°æ®",
                data=level_data.to_csv(index=False).encode('utf-8-sig'),
                file_name="å±‚çº§åˆ†å¸ƒ.csv",
                mime="text/csv",
                key="dl_level"
            )
        
        with col2:
            st.markdown("**ğŸ“ å†…å®¹é•¿åº¦åˆ†å¸ƒ**")
            lengths = [len(a.content or "") for a in atoms]
            buckets = {'0': 0, '1-100': 0, '101-500': 0, '501-1000': 0, '1000+': 0}
            for l in lengths:
                if l == 0:
                    buckets['0'] += 1
                elif l <= 100:
                    buckets['1-100'] += 1
                elif l <= 500:
                    buckets['101-500'] += 1
                elif l <= 1000:
                    buckets['501-1000'] += 1
                else:
                    buckets['1000+'] += 1
            length_data = pd.DataFrame({
                'é•¿åº¦åŒºé—´': list(buckets.keys()),
                'æ•°é‡': list(buckets.values())
            })
            st.bar_chart(length_data.set_index('é•¿åº¦åŒºé—´'))
            # ä¸‹è½½é•¿åº¦åˆ†å¸ƒæ•°æ®
            st.download_button(
                "â¬‡ï¸ ä¸‹è½½é•¿åº¦æ•°æ®",
                data=length_data.to_csv(index=False).encode('utf-8-sig'),
                file_name="å†…å®¹é•¿åº¦åˆ†å¸ƒ.csv",
                mime="text/csv",
                key="dl_length"
            )
        
        st.divider()
        
        # Row 3: Tree visualization with controls
        st.markdown("**ğŸŒ³ çŸ¥è¯†æ ‘ç»“æ„å›¾**")
        
        # æ·»åŠ æ§åˆ¶é€‰é¡¹
        ctrl_col1, ctrl_col2, ctrl_col3, ctrl_col4 = st.columns(4)
        with ctrl_col1:
            max_nodes = st.slider("æ˜¾ç¤ºèŠ‚ç‚¹æ•°", min_value=10, max_value=min(100, len(atoms)), value=min(40, len(atoms)), step=10)
        with ctrl_col2:
            layout_dir = st.selectbox("å¸ƒå±€æ–¹å‘", ["ä»ä¸Šåˆ°ä¸‹", "ä»å·¦åˆ°å³"], index=0)
        with ctrl_col3:
            show_level = st.multiselect("æ˜¾ç¤ºå±‚çº§", options=[1, 2, 3, 4, 5], default=[1, 2, 3], format_func=lambda x: f"H{x}")
        with ctrl_col4:
            st.markdown("")  # å ä½
            # ä¸‹è½½å®Œæ•´çŸ¥è¯†æ ‘ DOT æ–‡ä»¶
            full_dot = self._generate_graphviz_enhanced(atoms, "TB")
            st.download_button(
                "â¬‡ï¸ ä¸‹è½½å®Œæ•´å›¾è¡¨ (DOT)",
                data=full_dot,
                file_name="çŸ¥è¯†æ ‘.dot",
                mime="text/plain",
                key="dl_dot"
            )
        
        try:
            # æ ¹æ®é€‰é¡¹è¿‡æ»¤
            filtered_atoms = [a for a in atoms if a.level in show_level][:max_nodes]
            direction = "TB" if layout_dir == "ä»ä¸Šåˆ°ä¸‹" else "LR"
            dot_code = self._generate_graphviz_enhanced(filtered_atoms, direction)
            st.graphviz_chart(dot_code, use_container_width=True)
            st.caption(f"æ˜¾ç¤º {len(filtered_atoms)} / {len(atoms)} ä¸ªèŠ‚ç‚¹")
        except Exception as e:
            st.warning(f"å›¾è¡¨æ¸²æŸ“å¤±è´¥: {e}")
        
        st.divider()
        
        # Row 4: æ¥æºæ–‡ä»¶åˆ†å¸ƒï¼ˆå¦‚æœæœ‰å¤šä¸ªæ–‡ä»¶ï¼‰
        source_counts = {}
        for a in atoms:
            src = a.source_file
            source_counts[src] = source_counts.get(src, 0) + 1
        
        if len(source_counts) > 1:
            st.markdown("**ğŸ“ æ¥æºæ–‡ä»¶åˆ†å¸ƒ**")
            source_df = pd.DataFrame({
                'æ–‡ä»¶': list(source_counts.keys()),
                'åŸå­æ•°': list(source_counts.values())
            })
            st.bar_chart(source_df.set_index('æ–‡ä»¶'))
            st.download_button(
                "â¬‡ï¸ ä¸‹è½½æ¥æºåˆ†å¸ƒ",
                data=source_df.to_csv(index=False).encode('utf-8-sig'),
                file_name="æ¥æºæ–‡ä»¶åˆ†å¸ƒ.csv",
                mime="text/csv",
                key="dl_source"
            )
            st.divider()
        
        # Row 5: Data table with more info and download
        st.markdown("**ğŸ“‹ å®Œæ•´æ•°æ®è¡¨**")
        
        # ç”Ÿæˆå®Œæ•´æ•°æ®è¡¨
        full_df = pd.DataFrame([{
            'ID': a.id,
            'æ ‡é¢˜': a.title,
            'å±‚çº§': a.level,
            'å†…å®¹': a.content or "",
            'çˆ¶èŠ‚ç‚¹': a.parent_title or "",
            'çŸ¥è¯†è·¯å¾„': a.path,
            'æ¥æºæ–‡ä»¶': a.source_file,
            'å†…å®¹é•¿åº¦': len(a.content or ""),
            'å­èŠ‚ç‚¹æ•°': len([x for x in atoms if x.parent_id == a.id])
        } for a in atoms])
        
        # æ˜¾ç¤ºé¢„è§ˆï¼ˆå‰100æ¡ï¼‰
        display_df = full_df.head(100).copy()
        display_df['æ ‡é¢˜'] = display_df['æ ‡é¢˜'].str[:40] + display_df['æ ‡é¢˜'].str[40:].apply(lambda x: '...' if x else '')
        display_df['å†…å®¹'] = display_df['å†…å®¹'].str[:50] + display_df['å†…å®¹'].str[50:].apply(lambda x: '...' if x else '')
        st.dataframe(display_df[['æ ‡é¢˜', 'å±‚çº§', 'å†…å®¹é•¿åº¦', 'å­èŠ‚ç‚¹æ•°', 'çŸ¥è¯†è·¯å¾„', 'æ¥æºæ–‡ä»¶']], use_container_width=True, height=400)
        
        if len(atoms) > 100:
            st.caption(f"é¢„è§ˆå‰ 100 æ¡ï¼Œå…± {len(atoms)} æ¡")
        
        # ä¸‹è½½å®Œæ•´æ•°æ®
        dl_col1, dl_col2, dl_col3 = st.columns(3)
        with dl_col1:
            st.download_button(
                "â¬‡ï¸ ä¸‹è½½å®Œæ•´ CSV",
                data=full_df.to_csv(index=False).encode('utf-8-sig'),
                file_name="çŸ¥è¯†åŸå­å®Œæ•´æ•°æ®.csv",
                mime="text/csv",
                key="dl_full_csv"
            )
        with dl_col2:
            # JSON æ ¼å¼
            json_data = json.dumps([{
                'id': a.id,
                'title': a.title,
                'level': a.level,
                'content': a.content or "",
                'parent_id': a.parent_id,
                'parent_title': a.parent_title,
                'path': a.path,
                'source_file': a.source_file
            } for a in atoms], ensure_ascii=False, indent=2)
            st.download_button(
                "â¬‡ï¸ ä¸‹è½½ JSON",
                data=json_data,
                file_name="çŸ¥è¯†åŸå­.json",
                mime="application/json",
                key="dl_json"
            )
        with dl_col3:
            # Markdown æ ¼å¼
            md_content = self._generate_markdown_export(atoms)
            st.download_button(
                "â¬‡ï¸ ä¸‹è½½ Markdown",
                data=md_content.encode('utf-8'),
                file_name="çŸ¥è¯†åŸå­.md",
                mime="text/markdown",
                key="dl_md"
            )
    
    def _generate_markdown_export(self, atoms: List[KnowledgeAtom]) -> str:
        """ç”Ÿæˆ Markdown æ ¼å¼çš„çŸ¥è¯†åŸå­å¯¼å‡º"""
        lines = ["# çŸ¥è¯†åŸå­å¯¼å‡º\n"]
        lines.append(f"> å…± {len(atoms)} ä¸ªçŸ¥è¯†åŸå­\n")
        lines.append("---\n")
        
        # æŒ‰å±‚çº§ç»„ç»‡
        root_atoms = [a for a in atoms if a.parent_id is None]
        
        def render_atom(atom: KnowledgeAtom, depth: int = 0):
            prefix = "#" * (depth + 2)  # Start from ##
            lines.append(f"{prefix} {atom.title}\n")
            lines.append(f"**è·¯å¾„**: `{atom.path}`\n")
            if atom.content:
                lines.append(f"\n{atom.content}\n")
            lines.append("")
            
            # Render children
            children = [a for a in atoms if a.parent_id == atom.id]
            for child in children:
                render_atom(child, depth + 1)
        
        for root in root_atoms:
            render_atom(root)
        
        return '\n'.join(lines)
    
    def _generate_graphviz_enhanced(self, atoms: List[KnowledgeAtom], direction: str = "TB") -> str:
        """ç”Ÿæˆå¢å¼ºç‰ˆ Graphviz DOT æ ¼å¼å›¾è¡¨"""
        lines = [
            'digraph G {',
            f'    rankdir={direction};',
            '    bgcolor="transparent";',
            '    node [shape=box, style="rounded,filled", fontname="Microsoft YaHei,Arial", fontsize=10];',
            '    edge [color="#888888", arrowsize=0.7];',
            '    graph [ranksep=0.5, nodesep=0.3];'
        ]
        
        # Color mapping for levels with gradients
        colors = {
            1: '#ff6b6b',  # Red
            2: '#ffa94d',  # Orange
            3: '#ffd43b',  # Yellow
            4: '#69db7c',  # Green
            5: '#74c0fc'   # Blue
        }
        
        # Build parent set for edge validation
        atom_ids = {a.id for a in atoms}
        
        for atom in atoms:
            safe_title = atom.title[:20].replace('"', "'").replace('\n', ' ').replace('\\', '/')
            if len(atom.title) > 20:
                safe_title += '...'
            node_id = 'n' + atom.id[:8].replace('-', '')
            color = colors.get(atom.level, '#e9ecef')
            
            # Add node with tooltip
            tooltip = f"{atom.title}\\nå±‚çº§: H{atom.level}\\nå†…å®¹: {len(atom.content or '')} å­—"
            lines.append(f'    {node_id} [label="{safe_title}", fillcolor="{color}", tooltip="{tooltip}"];')
            
            # Add edge only if parent is in the filtered set
            if atom.parent_id and atom.parent_id in atom_ids:
                parent_id = 'n' + atom.parent_id[:8].replace('-', '')
                lines.append(f'    {parent_id} -> {node_id};')
        
        # Add legend
        lines.append('    subgraph cluster_legend {')
        lines.append('        label="å›¾ä¾‹";')
        lines.append('        style=dashed;')
        lines.append('        fontsize=9;')
        lines.append('        legend1 [label="H1 ç« èŠ‚", fillcolor="#ff6b6b"];')
        lines.append('        legend2 [label="H2 å°èŠ‚", fillcolor="#ffa94d"];')
        lines.append('        legend3 [label="H3 ä¸»é¢˜", fillcolor="#ffd43b"];')
        lines.append('        legend1 -> legend2 -> legend3 [style=invis];')
        lines.append('    }')
        
        lines.append('}')
        return '\n'.join(lines)
    
    def _render_export_section(self, atoms: List[KnowledgeAtom]):
        """æ¸²æŸ“å¯¼å‡ºé€‰é¡¹ - ä¼˜åŒ–ç‰ˆæœ¬ï¼ŒæŒ‰éœ€ç”Ÿæˆ"""
        st.subheader("ğŸ“¥ å¯¼å‡ºçŸ¥è¯†åŸå­")
        st.caption(f"æ¥æºæ–‡ä»¶: {st.session_state.source_file} | å…± {len(atoms)} ä¸ªçŸ¥è¯†åŸå­")
        
        # Three columns for export buttons
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("### ğŸ“„ CSV")
            st.caption("Excel å…¼å®¹æ ¼å¼")
            
            # æŒ‰éœ€ç”Ÿæˆ CSV
            if st.button("ç”Ÿæˆ CSV", key="gen_csv", use_container_width=True):
                with st.spinner("ç”Ÿæˆä¸­..."):
                    self._generate_csv(atoms)
            
            if st.session_state.csv_data:
                st.download_button(
                    label="â¬‡ï¸ ä¸‹è½½ CSV",
                    data=st.session_state.csv_data,
                    file_name=f"{st.session_state.source_file or 'export'}_atoms.csv",
                    mime="text/csv",
                    use_container_width=True
                )
        
        with col2:
            st.markdown("### ğŸ“š Obsidian")
            st.caption("çŸ¥è¯†åº“ ZIP åŒ…")
            
            # æŒ‰éœ€ç”Ÿæˆ ZIP
            if st.button("ç”Ÿæˆ ZIP", key="gen_zip", use_container_width=True):
                with st.spinner("ç”Ÿæˆä¸­..."):
                    self._generate_zip(atoms)
            
            if st.session_state.zip_data:
                st.download_button(
                    label="â¬‡ï¸ ä¸‹è½½ ZIP",
                    data=st.session_state.zip_data,
                    file_name=f"{st.session_state.source_file or 'export'}_obsidian.zip",
                    mime="application/zip",
                    use_container_width=True
                )
        
        with col3:
            st.markdown("### ğŸ¦ é£ä¹¦")
            st.caption("åŒæ­¥åˆ°å¤šç»´è¡¨æ ¼")
            if st.session_state.get('lark_configured'):
                if st.button("ğŸš€ åŒæ­¥åˆ°é£ä¹¦", key="lark_sync_btn", use_container_width=True, type="primary"):
                    self._export_lark(
                        atoms,
                        st.session_state.lark_app_id,
                        st.session_state.lark_app_secret,
                        st.session_state.lark_app_token,
                        st.session_state.lark_table_id
                    )
            else:
                st.info("è¯·å…ˆé…ç½®é£ä¹¦ API â†“")
        
        st.divider()
        
        # Lark config in expander
        with st.expander("âš™ï¸ é£ä¹¦ API é…ç½®", expanded=not st.session_state.get('lark_configured')):
            col1, col2 = st.columns(2)
            with col1:
                app_id = st.text_input("App ID", placeholder="cli_xxxxxxxxxx", key="lark_app_id_input")
                app_token = st.text_input("App Token", placeholder="bascnxxxxxxxxxx", key="lark_app_token_input")
            with col2:
                app_secret = st.text_input("App Secret", type="password", placeholder="xxxxxxxxxx", key="lark_app_secret_input")
                table_id = st.text_input("Table ID", placeholder="tblxxxxxxxxxx", key="lark_table_id_input")
            
            st.caption("ï¿½ é£ä¹¦å¤šç»´é…è¡¨æ ¼éœ€è¦çš„å­—æ®µï¼šåŸå­IDã€æ ‡é¢˜ã€å†…å®¹ã€å±‚çº§ã€çˆ¶èŠ‚ç‚¹ã€æ¥æºæ–‡ä»¶ã€çŸ¥è¯†è·¯å¾„")
            
            if st.button("ğŸ’¾ ä¿å­˜é…ç½®", use_container_width=True):
                if all([app_id, app_secret, app_token, table_id]):
                    st.session_state.lark_app_id = app_id
                    st.session_state.lark_app_secret = app_secret
                    st.session_state.lark_app_token = app_token
                    st.session_state.lark_table_id = table_id
                    st.session_state.lark_configured = True
                    st.success("âœ… é…ç½®å·²ä¿å­˜")
                    st.rerun()
                else:
                    st.error("è¯·å¡«å†™æ‰€æœ‰é…ç½®é¡¹")
    
    def _generate_csv(self, atoms: List[KnowledgeAtom]):
        """ç”Ÿæˆ CSV æ•°æ®"""
        try:
            exporter = CSVExporter()
            result = exporter.export(atoms)
            if result.success and result.file_path:
                with open(result.file_path, 'rb') as f:
                    st.session_state.csv_data = f.read()
                os.unlink(result.file_path)
                st.success("CSV ç”Ÿæˆå®Œæˆï¼")
        except Exception as e:
            st.error(f"ç”Ÿæˆå¤±è´¥: {e}")
    
    def _generate_zip(self, atoms: List[KnowledgeAtom]):
        """ç”Ÿæˆ Obsidian ZIP æ•°æ®"""
        try:
            exporter = ObsidianExporter()
            result = exporter.export(atoms)
            if result.success and result.file_path:
                with open(result.file_path, 'rb') as f:
                    st.session_state.zip_data = f.read()
                os.unlink(result.file_path)
                st.success("ZIP ç”Ÿæˆå®Œæˆï¼")
        except Exception as e:
            st.error(f"ç”Ÿæˆå¤±è´¥: {e}")
    
    def _export_lark(self, atoms: List[KnowledgeAtom], app_id: str, app_secret: str, app_token: str, table_id: str):
        """å¯¼å‡ºåˆ°é£ä¹¦"""
        try:
            with st.spinner("æ­£åœ¨åŒæ­¥åˆ°é£ä¹¦..."):
                exporter = LarkExporter(app_id, app_secret, app_token, table_id)
                result = exporter.export(atoms)
                
                if result.success:
                    st.success(result.message)
                else:
                    st.error(result.message)
        except Exception as e:
            st.error(f"åŒæ­¥å¤±è´¥: {str(e)}")


def main():
    """Main entry point."""
    app = KnowledgeAtomizerApp()
    app.run()


if __name__ == "__main__":
    main()
